{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainstorming\n",
    "\n",
    "Goal: Read my today twitter feed and extract the most important information. Then send it to my email with link for the important posts.\n",
    "\n",
    "Steps:\n",
    "1. [D] What important: new AI development or products, Tesla and stock market. Important news only. \n",
    "2. [D]Read twitter feed\n",
    "3. Extract important information\n",
    "4. Send email\n",
    "5. Schedule it\n",
    "6. Deploy it\n",
    "7. Test it\n",
    "8. Improve it\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_Key = os.getenv('twitter_api_key')\n",
    "API_Key_Secret = os.getenv('twitter_api_keySecret')\n",
    "access_token = os.getenv('twitter_access_token')\n",
    "access_token_secret = os.getenv('twitter_access_token_secret')\n",
    "\n",
    "# OAuth process, using the keys and tokens\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "   API_Key, API_Key_Secret, access_token, access_token_secret\n",
    ")\n",
    "\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Creation of the actual interface, using authentication\n",
    "api = tweepy.API(auth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_Key = os.getenv('twitter_api_key')\n",
    "API_Key_Secret = os.getenv('twitter_api_keySecret')\n",
    "access_token = os.getenv('twitter_access_token')\n",
    "access_token_secret = os.getenv('twitter_access_token_secret')\n",
    "\n",
    "# OAuth process, using the keys and tokens\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "   API_Key, API_Key_Secret, access_token, access_token_secret\n",
    ")\n",
    "\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Creation of the actual interface, using authentication\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline(count=200, tweet_mode='extended')  # Maximum count is 200\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Define keywords of interest\n",
    "keywords = ['Tesla', 'stock market', 'AI', 'artificial intelligence', 'breakthrough', 'breaking news']\n",
    "\n",
    "# Filter for tweets created today\n",
    "today_tweets = [tweet for tweet in public_tweets if tweet.created_at.date() == today]\n",
    "\n",
    "\n",
    "# Join all tweets into one string:\n",
    "all_tweets = \"\\n\".join([f\"Author: {tweet.user.name}, Tweet: {tweet.full_text}, URL: https://twitter.com/user/status/{tweet.id_str}\" for tweet in today_tweets])\n",
    "\n",
    "print(f\"All tweets:\\n {all_tweets}\")\n",
    "\n",
    "\n",
    "#Create an agent to read through all the tweets\n",
    "#Use the prompt to ask agent to return most important ones with link:\n",
    "def analyzer_agent():\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tweets:\n",
      "Date: 2023-05-04 06:12:01+00:00\n",
      "Author: Morten Just\n",
      "Tweet: https://t.co/px3ZK77lTN from @NiklasQuarfot and team comes close. Curious what the playground looks like! https://t.co/yrXjBpV7Nu\n",
      "URL: https://twitter.com/user/status/1654005941602246657\n",
      "\n",
      "Date: 2023-05-04 06:04:08+00:00\n",
      "Author: Morten Just\n",
      "Tweet: Found this sketch from August 2020. It's a GPT-3 prompt studio. It feels awfully dated, yet I kind of still need it. What similar products are out there today? https://t.co/RHqOfnrHax\n",
      "URL: https://twitter.com/user/status/1654003960372396033\n",
      "\n",
      "\n",
      "Decision: important\n",
      "\n",
      "Decision: important\n",
      "Collected 2 tweets from today.\n",
      "Found 0 important tweets.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import datetime\n",
    "import openai\n",
    "import string\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "API_Key = os.getenv('twitter_api_key')\n",
    "API_Key_Secret = os.getenv('twitter_api_keySecret')\n",
    "access_token = os.getenv('twitter_access_token')\n",
    "access_token_secret = os.getenv('twitter_access_token_secret')\n",
    "\n",
    "# OAuth process, using the keys and tokens\n",
    "auth = tweepy.OAuth1UserHandler(API_Key, API_Key_Secret, access_token, access_token_secret)\n",
    "\n",
    "# Creation of the actual interface, using authentication\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "class TweetAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model_name = 'gpt-3.5-turbo'\n",
    "\n",
    "    def is_important(self, text):\n",
    "    prompt = \"\"\"\n",
    "    I'm interested in AI developments,.\n",
    "    Is the tweet below important & related to my interest? (Only response \"important\" or \"not important\", no punctuation)):\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=self.model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt + text}\n",
    "        ]\n",
    "    )\n",
    "    decision = response['choices'][0]['message']['content'].lower()\n",
    "    decision = decision.translate(str.maketrans(\"\", \"\", string.punctuation)).strip()\n",
    "    print(f\"Decision: {decision}\")\n",
    "    return decision == \"important\"\n",
    "\n",
    "analyzer = TweetAnalyzer()\n",
    "\n",
    "public_tweets = api.home_timeline(count=10, tweet_mode='extended')  # Maximum count is 200\n",
    "\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Filter for tweets created today\n",
    "today_tweets = [tweet for tweet in public_tweets if tweet.created_at.date() == today]\n",
    "#print all the tweets:\n",
    "print(\"All tweets:\")\n",
    "for tweet in today_tweets:\n",
    "    print(f\"Date: {tweet.created_at}\")\n",
    "    print(f\"Author: {tweet.user.name}\")\n",
    "    print(f\"Tweet: {tweet.full_text}\")\n",
    "    print(f\"URL: https://twitter.com/user/status/{tweet.id_str}\\n\")\n",
    "    \n",
    "    \n",
    "# Further filter for \"important\" tweets\n",
    "important_tweets = [tweet for tweet in today_tweets if analyzer.is_important(tweet.full_text)]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Collected {len(today_tweets)} tweets from today.\")\n",
    "print(f\"Found {len(important_tweets)} important tweets.\")\n",
    "\n",
    "for tweet in important_tweets:\n",
    "    print(f\"Date: {tweet.created_at}\")\n",
    "    print(f\"Author: {tweet.user.name}\")\n",
    "    print(f\"Tweet: {tweet.full_text}\")\n",
    "    print(f\"URL: https://twitter.com/user/status/{tweet.id_str}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
